{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121a7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0b623f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beac7ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = open(\"./access_key/cognitive_api_key.txt\").read()\n",
    "endpoint = open(\"./access_url/cognitive_api_url.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9485ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate_client():\n",
    "    ta_credential = AzureKeyCredential(key)\n",
    "    text_analytics_client = TextAnalyticsClient(\n",
    "            endpoint=endpoint, \n",
    "            credential=ta_credential)\n",
    "    return text_analytics_client\n",
    "\n",
    "client = authenticate_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b649a8cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: positive\n",
      "Overall scores: positive=1.00; neutral=0.00; negative=0.00 \n",
      "\n",
      "Sentence: I had the best day of my life.\n",
      "Sentence 1 sentiment: positive\n",
      "Sentence score:\n",
      "Positive=1.00\n",
      "Neutral=0.00\n",
      "Negative=0.00\n",
      "\n",
      "Sentence: I wish you were there with me.\n",
      "Sentence 2 sentiment: neutral\n",
      "Sentence score:\n",
      "Positive=0.21\n",
      "Neutral=0.77\n",
      "Negative=0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis_example(client):\n",
    "\n",
    "    documents = [\"I had the best day of my life. I wish you were there with me.\"]\n",
    "    response = client.analyze_sentiment(documents=documents)[0]\n",
    "    print(\"Document Sentiment: {}\".format(response.sentiment))\n",
    "    print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "        response.confidence_scores.positive,\n",
    "        response.confidence_scores.neutral,\n",
    "        response.confidence_scores.negative,\n",
    "    ))\n",
    "    for idx, sentence in enumerate(response.sentences):\n",
    "        print(\"Sentence: {}\".format(sentence.text))\n",
    "        print(\"Sentence {} sentiment: {}\".format(idx+1, sentence.sentiment))\n",
    "        print(\"Sentence score:\\nPositive={0:.2f}\\nNeutral={1:.2f}\\nNegative={2:.2f}\\n\".format(\n",
    "            sentence.confidence_scores.positive,\n",
    "            sentence.confidence_scores.neutral,\n",
    "            sentence.confidence_scores.negative,\n",
    "        ))\n",
    "          \n",
    "sentiment_analysis_example(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9f7465a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_request(document):\n",
    "    if len(document) > 10:\n",
    "        all_doc_send=[]\n",
    "        response=[]\n",
    "        range_10 = [i for i in range(0,len(document)+1,10)]\n",
    "        for i in range(1,len(range_10)):\n",
    "            all_doc_send.append(document[range_10[i - 1 ]:range_10[i]])\n",
    "        for doc in all_doc_send:\n",
    "            response.extend(client.analyze_sentiment(documents=doc))\n",
    "    else:\n",
    "        response = client.analyze_sentiment(documents=document)\n",
    "    return response\n",
    "\n",
    "def format_response(response):\n",
    "    for resp in response:\n",
    "        print(\"Document Sentiment: {}\".format(resp.sentiment))\n",
    "        print(\"Overall scores: positive={0:.2f}; neutral={1:.2f}; negative={2:.2f} \\n\".format(\n",
    "            resp.confidence_scores.positive,\n",
    "            resp.confidence_scores.neutral,\n",
    "            resp.confidence_scores.negative,\n",
    "        ))\n",
    "        \n",
    "def get_pred(resp,get_neutral=False):\n",
    "    positive = resp.confidence_scores.positive\n",
    "    neutral = resp.confidence_scores.neutral\n",
    "    negative = resp.confidence_scores.negative\n",
    "    if get_neutral :\n",
    "        if (positive > neutral) & (positive > negative):\n",
    "            return \"good\"\n",
    "        elif (negative > neutral) & (negative > positive):\n",
    "            return \"bad\"\n",
    "        else:\n",
    "            return \"neutral\"\n",
    "    else:\n",
    "        if positive > negative:\n",
    "            return \"good\"\n",
    "        else:\n",
    "            return \"bad\"\n",
    "    \n",
    "def get_response_prediction(response,get_neutral=False):\n",
    "    dic={\n",
    "        \"good_score\":[],\n",
    "        \"neutral_score\":[],\n",
    "        \"bad_score\":[],\n",
    "        \"prediction\":[],\n",
    "    }\n",
    "    for resp in response:\n",
    "        dic[\"good_score\"].append(resp.confidence_scores.positive)\n",
    "        dic[\"neutral_score\"].append(resp.confidence_scores.neutral)\n",
    "        dic[\"bad_score\"].append(resp.confidence_scores.negative)\n",
    "        dic[\"prediction\"].append(get_pred(resp,get_neutral=get_neutral))\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8184148",
   "metadata": {},
   "source": [
    "# Benchmark azure cognitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca26f129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionnalité : (4000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chillin @ the beach with my girl brit-brit wat...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@indraherlambang really wanna say that ure lik...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@ambermac Gotta love Brad Pitt's performance, ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Just realized that Matthew Sweet &amp;amp; Susanna...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@marksphone sorry, meant that to come from my ...</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment\n",
       "0  Chillin @ the beach with my girl brit-brit wat...      good\n",
       "1  @indraherlambang really wanna say that ure lik...      good\n",
       "2  @ambermac Gotta love Brad Pitt's performance, ...      good\n",
       "3  Just realized that Matthew Sweet &amp; Susanna...      good\n",
       "4  @marksphone sorry, meant that to come from my ...      good"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = pd.read_csv(\"./data/sample_test_dataset.csv\",index_col=0)\n",
    "print(\"Dimensionnalité :\",test_sample.shape)\n",
    "test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a298ac33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good    2000\n",
       "bad     2000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d4c128",
   "metadata": {},
   "source": [
    "## Test avec 10 tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b03ab24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Chillin @ the beach with my girl brit-brit watchin the laker game n finally enjoyin this cali weather \n",
      "\n",
      "- @indraherlambang really wanna say that ure like Ryan Seacrest (Indo version). It's a compliment. Hope u'll be as succes as him! \n",
      "\n",
      "- @ambermac Gotta love Brad Pitt's performance, too. Subtitles or not. \n",
      "\n",
      "- Just realized that Matthew Sweet &amp; Susanna Hoffs have a second volume of &quot;Under the Covers&quot; streeting this summer.  Yay!\n",
      "\n",
      "- @marksphone sorry, meant that to come from my personal acct! people first \n",
      "\n",
      "- ftw. displacement. instantaneous. What the fuck is terminal velocity ? \n",
      "\n",
      "- is chillin in bed watching dog the bounty hunter! \n",
      "\n",
      "- Mmmmmmm having my mom's pho right now \n",
      "\n",
      "- Getting sushi with @nicurnmama \n",
      "\n",
      "- @ajsouthern DELICIOUS!!  Thanks! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "document_send = test_sample.iloc[:10][\"text\"].tolist()\n",
    "y_true = test_sample.iloc[:10][\"sentiment\"].tolist()\n",
    "for sentence in document_send:\n",
    "    print(\"-\",sentence)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc353711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.95; neutral=0.05; negative=0.00 \n",
      "\n",
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.97; neutral=0.03; negative=0.00 \n",
      "\n",
      "Document Sentiment: mixed\n",
      "Overall scores: positive=0.50; neutral=0.06; negative=0.44 \n",
      "\n",
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.80; neutral=0.18; negative=0.02 \n",
      "\n",
      "Document Sentiment: negative\n",
      "Overall scores: positive=0.00; neutral=0.00; negative=1.00 \n",
      "\n",
      "Document Sentiment: mixed\n",
      "Overall scores: positive=0.49; neutral=0.01; negative=0.50 \n",
      "\n",
      "Document Sentiment: neutral\n",
      "Overall scores: positive=0.33; neutral=0.66; negative=0.01 \n",
      "\n",
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.68; neutral=0.27; negative=0.05 \n",
      "\n",
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.70; neutral=0.25; negative=0.05 \n",
      "\n",
      "Document Sentiment: positive\n",
      "Overall scores: positive=0.99; neutral=0.01; negative=0.00 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "format_response(send_request(document_send))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d43dc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['good', 'good', 'good', 'good', 'bad', 'bad', 'good', 'good', 'good', 'good']\n"
     ]
    }
   ],
   "source": [
    "dic_response = get_response_prediction(send_request(document_send))\n",
    "print(dic_response[\"prediction\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "955f475b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report,roc_auc_score\n",
    "def benchmark(dic_response,y_true):\n",
    "    y_pred = dic_response[\"prediction\"]\n",
    "    print(\"accuracy score :\",accuracy_score(y_true,y_pred))\n",
    "    print(classification_report(y_true,y_pred))\n",
    "    return pd.DataFrame(confusion_matrix(y_true,y_pred),columns=[\"good\",\"bad\"],index=[\"good\",\"bad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1612c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dic_response[\"prediction\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "087ab348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy score :\",accuracy_score(y_true,y_pred))\n",
    "# print(classification_report(y_true,y_pred))\n",
    "# pd.DataFrame(confusion_matrix(y_true,y_pred),columns=[\"good\",\"bad\"],index=[\"good\",\"bad\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89d7de",
   "metadata": {},
   "source": [
    "## tous les tweets\n",
    "\n",
    "Le coût de ce service est de 0.87€ pour 1000 requêtes, avec ce test nous somme à 4000 requêtes sois un total de 3.48€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8ab5c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_send = test_sample[\"text\"].tolist()\n",
    "y_true = test_sample[\"sentiment\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e57c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_response = get_response_prediction(send_request(document_send))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6627d12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.70975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         bad       0.74      0.64      0.69      2000\n",
      "        good       0.68      0.78      0.73      2000\n",
      "\n",
      "    accuracy                           0.71      4000\n",
      "   macro avg       0.71      0.71      0.71      4000\n",
      "weighted avg       0.71      0.71      0.71      4000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>bad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>1276</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>437</td>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      good   bad\n",
       "good  1276   724\n",
       "bad    437  1563"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark(dic_response,y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "882eeee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {\"bad\":0,\"good\":1}\n",
    "y_test = [dic[y] for y in y_true]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba5354e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUROC score : 0.743618625\n"
     ]
    }
   ],
   "source": [
    "print(\"AUROC score :\",roc_auc_score(y_test, dic_response[\"good_score\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4cd57",
   "metadata": {},
   "source": [
    "Se modèle est entrainer principalement sur un échantillon large et non spécialisé, la détéction de sentiment des tweets ici est assez médiocre avec une accuracy de seulement 0.7 et une AUROC de seulement 0.74 ( calcul de l'auroc car le service cognitive mesure le degré de sentiment positif, négatif et neutre, la valeur AUROC ici prend plus de sens )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00cad8c2",
   "metadata": {},
   "source": [
    "# Benchmark des approches de score de sentiments\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./img/logo-oc.png\" style=\"display:inline-block;height: 120px;\">\n",
    "    <img src=\"./img/logo-microsoft-scaled.jpg\" style=\"height: 60px; display:inline-block;\">\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align:right; font-style: italic; font-size: 11px\">\n",
    "TUCCIO Sébastien 2021-2022 [OC-Ingénieur IA]\n",
    "</div>\n",
    "\n",
    "# Sommaire :\n",
    "<ul>\n",
    "<li><a href=\"#Présentation-du-contexte-(fictif)\">Présentation du contexte</a></li>\n",
    "<li><a href=\"#Réalisation-des-solutions\">Réalisation des solutions</a>\n",
    "    <ul>\n",
    "        <li><a href=\"#Cognitive-Services-Azure\">Cognitive Services Azure</a></li>\n",
    "        <li><a href='#Module-\"no-code\"'>Module \"no-code\"</a></li>\n",
    "        <li><a href=\"#Algorithme-avancé\">Algorithme avancé</a></li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li><a href=\"#Présentation-des-résultats\">Présentation des résultats</a>\n",
    "    <ul>\n",
    "        <li><a href=\"#Performance\">Performance</a></li>\n",
    "        <li><a href=\"#Coût-utilisation\">Coût utilisation</a></li>\n",
    "    </ul>\n",
    "</li>\n",
    "<li><a href=\"#Conclusion\">Conclusion</a></li>\n",
    "</ul>\n",
    "\n",
    "## Présentation du contexte (fictif)\n",
    "\n",
    "<p style=\"text-align:center\">La société <span style=\"font-weight: bold\">\"Air Paradis\"</span> souhaite pouvoir <span style=\"font-weight: bold\">detecter les bads buzz via le réseaux twitter</span>. Pour ce faire Air Paradis requête une entreprise de conseil spécialisée sur les problématiques du marketing digital (dont je fais partie en tant qu'ingénieur IA) pour obtenir <span style=\"font-weight: bold\">une solution lui permettant d'obtenir le sentiment associée à un tweet</span>.</p>\n",
    "\n",
    "<br>\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./img/logo.png\" style=\"display:inline-block; height: 150px;\">\n",
    "    &\n",
    "    <img src=\"./img/twitter-logo.jpg\" style=\"height: 100px; display:inline-block;\">\n",
    "</div>\n",
    "\n",
    "\n",
    "<p style=\"text-align:center\">Pour ce faire <span style=\"font-weight: bold\">l'entreprise ne dispose pas de jeu de données</span>. Le jeu de données sera donc un jeu de données présent sur <span style=\"font-weight: bold\">Kaggle</span> : <a href=\"https://www.kaggle.com/kazanova/sentiment140/download\" target=\"_blank\">\"Sentiment140 dataset with 1.6 miilion tweets\"</a> qui met est disposition <span style=\"font-weight: bold\">1.600.000 tweet labélisé avec un sentiment (négatif ou positif)</span>.</p>\n",
    "\n",
    "### Présentation du jeu de données\n",
    "\n",
    "<p style=\"text-align:center\">Le jeu de données source contient 6 colonnes (target, id, date, flag, user, text) et pour chaque ligne un tweet associé (colonne \"text\"), cependant seulement 2 colonnes sont intéressantes dans note contexte, on prendras donc la colonne \"target\" qui indique le sentiment associée au tweet (0 pour un tweet négatif et 4 pour un tweet positif) et également la colonne \"text\" qui correspond au tweet.<br>\n",
    "<br>\n",
    "Les autres colonnes peuvent cependant nous donner des informations sur la fréquences des tweet, et la durée sur la quelle à était récupéré le jeu de donénes</p>\n",
    "\n",
    "<img src=\"./img/nb_tweet_by_day.png\" style=\"margin-left:auto; margin-right:auto; display: block; height: 250px\">\n",
    "\n",
    "<p style=\"text-align:center\">Par exemple, on voit ici que le jeu de donnée est sur une durée de 3 mois et que il y a des jours où le nombre de tweet journalier explose (sûrment liée à un évenement ou liée à la récupération des données).</p>\n",
    "\n",
    "<img src=\"./img/nb_word_tweet.png\" style=\"margin-left:auto; margin-right:auto; display: block; height: 250px\">\n",
    "\n",
    "<p style=\"text-align:center\">Les tweets par définition sont des petits textes, on vois ici que les tweets sont très courts avec maximum 150 mot par tweets.<br>\n",
    "Après avoir fait un nettoyage rapide des différent tweet voici les nuages de mot qui en ressorte sur les \"bad tweets\"  et les \"good tweets\"  :</p>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./img/wordcloud_bad.png\" style=\"display:inline-block;height: 250px;\">\n",
    "    <img src=\"./img/wordcloud_good.png\" style=\"display:inline-block;height: 250px\">\n",
    "</div>\n",
    "\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Pour ce projet on utilisera principalement Microsoft Azure avec l'espace de travail Machine Learning pour réaliser un benchmark des différentes solutions applicables (module no-code, cognitif service, modèles personalisé) puis les déployer rapidement sous forme d'API utilisable pour la récupération de sentiment d'un tweet (Data mining).\n",
    "Pour faire un benchmark efficace il conviens de définir une métrique adapté, ici nous souhaitons obtenir un <span style=\"font-weight: bold\">score de sentiment associée à un tweet et non une simple réponse binaire</span>, on partira donc sur la métrique <span style=\"font-weight: bold\">AUC (Area Under the Curve) ROC (Receiver Operating characteristic Curve)</span> qui permet d'avoir une mesure plus précise du score de sentiment, on analysera également la <span style=\"font-weight: bold\">matrice de confusion</span> quand les résultat sont assez simillaire afin de choisir le résultat qui favorise les bad tweets.\n",
    "</p>\n",
    "\n",
    "### Azure Machine Learning & Gognitive Service\n",
    "\n",
    "<img src=\"./img/Microsoft-Azure-Logo.jpg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 100px\">\n",
    "<p style=\"text-align:center\">\n",
    "Azure fournie un espace de travail pour le Machine Learning qui comprend une architecture proposant de nombreux service comme la création de pipeline ML, la création d'un modèle automatique (Automated ML), ou encore de créer des instances web pour mettre en place une API réaliser depuis Automated ML, studio drag & drop ou encore un notebook Azure ou local.<br>\n",
    "Le schéma ci-dessous est une représentation de l'architecture fournie par Azure Machine Learning, on y retrouve les composante (dependencies) qu'utilise Azure Machine Learning, les ressources que l'on peux créer (Container ACI/ Cluster AKS), et le plus important les possibilité du workspace, avec la création d'environement (il existe déjà des environements pré-définis), des \"Experiments\" qui permettent l'entrainement de modèle, la création de pipeline complete le stockage de modèle et jeu de données et enfin la mise en place d'Endpoint pour exposer les différent modèles créer.\n",
    "</p>\n",
    "\n",
    "<img src=\"./img/architecture.svg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 400px\">\n",
    "\n",
    "<p style=\"text-align:center\">Il existe également un service Clé en main \"Cognitive Services Azure\" qui est une API permettant de faire de la traduction de texte, détéction de language, Data Mining, Vision par ordinateur...\n",
    "On aborderas cette solution plus en détail dans la partie Réalisation des solutions</p>\n",
    "\n",
    "<img src=\"./img/cognitive_service_logo.jpg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 200px\">\n",
    "\n",
    "\n",
    "## Réalisation des solutions\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Pour la réalisation des tests, j'ai créer un jeu de données de 4000 tweets stratifiés avec 2000 bad tweet et 2000 good tweet. Dans chacun des résultat présenté ci-dessous le jeu de donnée à était séparer avant tout traitement et l'entrainement à était effectuer sans ces 4000 tweets pour les modèles entrainé.\n",
    "</p>\n",
    "\n",
    "### Cognitive Services Azure\n",
    "<p style=\"text-align:center\">\n",
    "Pour cette partie rien de complexe étant une solution clé en main, pour créer une ressource cognitive il suffit de se rendre sur le portail azure et créer une ressource <a href=\"https://portal.azure.com/#create/Microsoft.CognitiveServicesAllInOne\" target=\"_blank\">Cognitive Services</a>.\n",
    "Une fois créé, il suffit de récupérer le \"Endpoint\" et \"Keys\" d'accès au service, après ça il suffit de suivre <a href=\"https://docs.microsoft.com/fr-fr/azure/cognitive-services/language-service/sentiment-opinion-mining/quickstart?pivots=programming-language-python\" target=\"_blank\">la documentation</a> pour l'implémenter puis l'utiliser.<br><br>\n",
    "Ce service nous retourne 4 informations, la prédiction (neutral, bad, good) puis le scores associés (bad, neutral, good).<br>\n",
    "Comme notre jeu de données contient uniquement des données binaire (bad/good) on utilisera une régression logistique sur les 3 score du service pour prédire les labels binaire associés et pouvoir obtenir un score de sentiment de mauvais à bon tweet et une réponse binaire.<br>\n",
    "Voici les résutlats du service cognitive :\n",
    "</p>\n",
    "\n",
    "<img src=\"./img/benchmark_cognitive_service.jpg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 250px\">\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "On obtiens un score AUC de 0.77 ce qui reste correct pour un service généraliste qu'offre le Cognitive Service. si on regarde en détail on remarque cependant un point très positif sur la matrice de confusion est que le Cognitive Service detecte très bien les \"bad\" tweets avec une précision de 0.77.<br>\n",
    "On utilisera se modèle comme \"Baseline\" afin de comparer l'utilité d'investir du temps dans la création d'un modèle personalisé.\n",
    "</p>\n",
    "\n",
    "### Module \"no-code\"\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Sur Azure il existe 2 module \"no-code\", une version drag & drop que l'on vas présenter en détail puis une version automatique (Automated ML) qui créer une pipeline/modèle complet en 1 click depuis azure Machine Learning déployable également en 1 click.<br>\n",
    "<br>\n",
    "Pour faire la pipeline drag & drop on utilisera la version \"classique\" de \"azureml\" <span style=\"color:red\">(/!\\ cette version sera supprimé en 2024 /!\\)</span>.\n",
    "Il est possible également de réaliser une pipeline sur la nouvelle version (<a href=\"https://docs.microsoft.com/fr-fr/azure/machine-learning/tutorial-designer-automobile-price-train-score\" target=\"_blank\">avec un tutoriel sur la création</a> ET <a href=\"https://docs.microsoft.com/fr-fr/azure/machine-learning/tutorial-designer-automobile-price-deploy\" target=\"_blank\">un tutoriel sur le déployement</a>) mais il est nécessaire de créer une instance de calcul pour réaliser la pipeline puis utiliser un container ACI ou cluster AKS pour le déployement qui sont payant...<br>\n",
    "<br>\n",
    "Pour le module drag & drop \"classique\" <a href=\"https://studio.azureml.net/\" target=\"_blank\">\"studio.azureml.net\"</a> il suffit de créer une nouvelle expérience puis de déplacer les modules que l'on souhaite appliquer sur notre pipeline comme le montre le gif ci-dessous (le gif présente la nouvelle version sur Azure Machine Learning, mais le fonctionnement est identique).\n",
    "</p>\n",
    "<img src=\"./img/designer-drag-and-drop.gif\" style=\"margin-left:auto; margin-right:auto; display: block; height: 400px\">\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Pour ce module j'ai réaliser un algorithme \"simple\" de Régression Logistique.<br>\n",
    "Pour ce faire, j'ai d'abord : <br>\n",
    "Importer le jeu de données que j'ai stocké dans un compte de stockage Azure (fichier Blob) qui contient un échantillion réduit du jeu de données (10.000 tweets parfaitement stratifié entre les bons et mauvais tweets).<br>\n",
    "Après ça j'ai effectuée un nettoyage des données textuelles en supprimant les URL, faisant de la lemmatization, supprimant les stop words...<br>\n",
    "Après ça j'ai créer ma matrice TF-IDF et générer un jeu de données du vocabulaire que j'ai réutiliser par la suite<br>\n",
    "Puis j'ai entrainer mon jeu de données grâce à cette matrice TF-IDF et je renvois ensuite les résutlat du modèle.<br>\n",
    "<br>\n",
    "Ci-dessous voici la pipeline complète utiliser pour le déployement :</p>\n",
    "<img src=\"./img/studio_classic_web_service.jpg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 500px\">\n",
    "\n",
    "<p style=\"text-align:center\">Après ça j'ai testé depuis l'API l'algorithme toujours sur le même jeu de donnée de comparaison, on obtiens les résultats suivant :</p>\n",
    "\n",
    "<img src=\"./img/benchmark_no_code.jpg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 250px\">\n",
    "\n",
    "<p style=\"text-align:center\">Les résultats sont moins bon que le cognitive services mais pourrais être meilleur/équivalent si le jeu de données serais plus important.</p>\n",
    "\n",
    "### Algorithme avancé\n",
    "#### Démarche des recherches\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "1) La première étape consiste à vérifier la pertinance de faire de la Lemmatisation ou du Stemming pour l'amélioration d'algorithme de DL type (Embedding -> LSTM -> Dense)<br>\n",
    "<br>\n",
    "<br>\n",
    "2) Après ça on effectue un benchmark de plusieurs types d'algorithme DL afin de trouver la meilleur structure :<br>\n",
    "<br>\n",
    "- Modèle DL multicouche<br>\n",
    "- Modèle RNN classique<br>\n",
    "- Modèle LSTM Embedding générer automatiquement<br>\n",
    "- Modèle LSTM avec Word2Vec <br>\n",
    "- Modèle LSTM avec Glove<br>\n",
    "- Modèle Pré-entrainer BERT (Transfer-Learning)<br>\n",
    "<br>\n",
    "3) Après avoir analysé plusieurs modèles on choisira un modèle afin de l'optimiser.<br>\n",
    "<br>\n",
    "4) Une fois la recherche d'hyperparamètre effectué, on sauvegardera notre modèle<br>\n",
    "</p>\n",
    "\n",
    "#### Résultat\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Pour faire un résumé simple les structure LSTM apporte de bien meilleur résultat que les RNN ou des modèle classique multicouche, ensuite les méthode de Lemmatization et Stemming font perdre de l'information et donc ici de la performance, un clean classique avec simplement du regex apporte de meilleur résultat! <br>\n",
    "Pour les structure Embedding la méthode Word2Vec semblent plus performante, et enfin Bert pré-entrainer obtient de très bon résultat mais reste moins performant que Word2vec avec une couche LSTM, il serais également possible de réentrainer la couche Bert avec le système d'attention qui est parfaitement explicité sur le site <a href=\"https://lesdieuxducode.com/blog/2019/4/bert--le-transformer-model-qui-sentraine-et-qui-represente\" target=\"_blank\">\"Les Dieux du ${code}\"</a>.<br>\n",
    "Au final le meilleur est le Modèle LSTM avec la couche Embedding Word2Vec, et voici les résultats sur le jeu de données test :\n",
    "</p>\n",
    "\n",
    "<img src=\"./img/benchmark_avanced.jpg\" style=\"margin-left:auto; margin-right:auto; display: block; height: 250px\">\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Ce modèles est meilleur en tout points avec un score AUC de 0.92 et 0.84 de précision sur les bad tweets! \n",
    "</p>\n",
    "\n",
    "## Présentation des résultats\n",
    "\n",
    "### Performance\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Voici le résultat des différentes solutions testé en terme de performance:\n",
    "</p> \n",
    "\n",
    "<img src=\"./img/benchmark_solution.png\" style=\"margin-left:auto; margin-right:auto; display: block; height: 500px\">\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Cette fiche résumé est suffisament parlante, on voit que les modèle word2vec_lstm et meilleur que tous les autres modèles (Glove et meilleur à l'apprentissage mais généralise moins bien que Word2Vec), Bert peut largement être amélioré mais on vois que le temps d'entrainement avec un modèle pré-entrainer et déjà très important, je ne suis donc pas partie sur cette solution pour ne pas prendre plusiseurs jours sur l'apprentissage.\n",
    "</p> \n",
    "\n",
    "### Coût utilisation\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Voici les fiches de coût éstimées pour une utilisation à 1.000.000 de tweet mensuel:\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"./img/pricing_cognitif_month.jpg\" style=\"display:inline-block;height: 450px;\">\n",
    "    <img src=\"./img/pricing_aks_month.jpg\" style=\"display:inline-block;height: 600px\">\n",
    "</div>\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "<p style=\"text-align:center\">\n",
    "Si on réalise une matrice de choix, le plus pertinent est le modèle avancée malgré sont coût de mise en place le plus important (Prix d'un Ingenieur IA/consultant Data pour travailler sur le sujet), il obtient les meilleurs résultats et un coût d'utilisation (à forte utilisation) assez faible en production!\n",
    "</p>\n",
    "\n",
    "<img src=\"./img/matric_choix.png\" style=\"margin-left:auto; margin-right:auto; display: block; height: 500px\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
